# Phase 3: 比較分析と自己学習

## 目的
Phase 1の「AIレビューレポート」とPhase 2の「SonarQube分析結果」を比較し、AIが見逃した問題点を特定して自己学習サマリーを生成する。

## あなた（AIアシスタント）実行項目

### 1. データ読み込みと前処理
- `temp/ai_review_report_[timestamp].md` を読み込み
- `temp/sonarqube_data_[timestamp].json` を読み込み
- 両データを比較可能な形式に正規化

### 2. 問題検出の対照分析

#### SonarQubeが検出してAIが見逃した問題の特定
以下の手順で差分を抽出：

1. **セキュリティ脆弱性の比較**
   - SonarQube VULNERABILITY vs AIレビューのセキュリティ検査結果
   - 見逃したVULNERABILITYを特定

2. **バグ・品質問題の比較**
   - SonarQube BUG vs AIレビューのコード品質検査結果
   - 見逃したBUGを特定

3. **コードスメルの比較**
   - SonarQube CODE_SMELL vs AIレビューの保守性検査結果
   - 見逃したCODE_SMELLを特定

### 3. 見逃し原因の自己分析

各見逃した問題について以下の分析を実行：

#### 問題分類
```markdown
## 見逃し問題: [SonarQubeルール名]
### 基本情報
- ファイル: [ファイルパス]
- 行番号: [行番号]
- 重要度: [BLOCKER/CRITICAL/MAJOR]
- カテゴリ: [VULNERABILITY/BUG/CODE_SMELL]

### 問題詳細
- SonarQube検出内容: [詳細説明]
- 該当コード: ```[言語]
[問題のあるコード]
```

### 見逃し原因分析
1. **パターン認識の欠如**
   - このコードパターンがAIの既知パターンに含まれていない
   - ナレッジベースに該当するルールが不足

2. **コンテキスト理解不足**
   - コードの文脈や周辺環境の考慮が不十分
   - フレームワーク固有の問題への対応不足

3. **優先度判定の誤り**
   - 問題の重要度評価が不適切
   - リスクレベルの見積もりが甘い
```

#### 改善策の立案
```markdown
### 学習改善策
1. **新規ルール追加**
   - 追加すべきチェック項目: [具体的なルール]
   - 検出パターン: [正規表現や検索条件]

2. **既存ルール強化**
   - 強化対象ルール: [既存ルール名]
   - 改善内容: [具体的な改善案]

3. **コンテキスト認識向上**
   - 考慮すべき要素: [フレームワーク、ライブラリ、環境]
   - 分析観点の追加: [新しい観点]
```

### 4. 自己学習サマリー生成

#### 学習サマリー構造
```markdown
# AI自己学習サマリー - [実行日時]

## 分析対象
- 対象ファイル: [ファイルパス]
- AI検出問題数: [数値]
- SonarQube検出問題数: [数値]
- 見逃し問題数: [数値]

## 見逃しパターン統計
### セキュリティ脆弱性
- 見逃し数: [数値]/[総数]
- 主な見逃しパターン:
  - [パターン1]: [発生回数]
  - [パターン2]: [発生回数]

### コード品質
- 見逃し数: [数値]/[総数]
- 主な見逃しパターン:
  - [パターン1]: [発生回数]
  - [パターン2]: [発生回数]

### 保守性
- 見逃し数: [数値]/[総数]
- 主な見逃しパターン:
  - [パターン1]: [発生回数]
  - [パターン2]: [発生回数]

## 新規学習ルール
### 追加すべきチェック項目
1. **[ルール名1]**
   - カテゴリ: [セキュリティ/品質/保守性]
   - 検出条件: [具体的条件]
   - 例外条件: [除外条件]
   - 重要度: [高/中/低]

2. **[ルール名2]**
   - カテゴリ: [セキュリティ/品質/保守性]
   - 検出条件: [具体的条件]
   - 例外条件: [除外条件]
   - 重要度: [高/中/低]

## 強化すべき既存ルール
1. **[既存ルール名]**
   - 現在の問題: [不足点]
   - 改善案: [具体的改善内容]
   - 影響範囲: [対象言語/フレームワーク]

## 次回改善アクション
- [ ] ai-review-knowledge-baseへの新規ルール追加
- [ ] 既存ルールの更新
- [ ] コンテキスト分析機能の強化
- [ ] 優先度評価ロジックの調整

## 学習効果測定指標
- 改善前見逃し率: [パーセンテージ]
- 目標見逃し率: [パーセンテージ]
- 次回検証予定: [日付]
```

### 5. 品質メトリクス計算
以下の指標を算出して学習効果を定量化：

```json
{
  "quality_metrics": {
    "precision": 0.85,  // AI検出のうち正確だった割合
    "recall": 0.78,     // 実際の問題のうちAIが検出した割合
    "f1_score": 0.81,   // 総合評価指標
    "false_positive_rate": 0.15,  // 誤検出率
    "false_negative_rate": 0.22,  // 見逃し率
    "improvement_areas": [
      "security_vulnerability_detection",
      "framework_specific_issues",
      "context_aware_analysis"
    ]
  }
}
```

## 出力ファイル
- `temp/learning_summary_[timestamp].md` (学習サマリー)
- `temp/quality_metrics_[timestamp].json` (品質メトリクス)

## 次フェーズとの連携
Phase 4 (ナレッジベース更新) で使用するため、学習サマリーを構造化された形式で出力。

## 成功基準
- 全見逃し問題の特定と分析完了
- 見逃し原因の具体的な特定
- 実行可能な改善策の提案
- 定量的な学習効果測定指標の算出
- Phase 4で活用可能な構造化された学習サマリーの生成
