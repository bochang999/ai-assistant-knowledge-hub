#!/usr/bin/env python3
"""
Phase 2: Project Context Analysis
BOC-95ã«åŸºã¥ãæ®µéšçš„å•é¡Œè§£æ±ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚·ã‚¹ãƒ†ãƒ 

ç›®çš„: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚¹ã‚­ãƒ£ãƒ³ã€ç›®çš„ãƒ»æ„å›³ã®ç†è§£ã€æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ç‰¹å®š
"""

import os
import json
import sys
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import re


class ProjectAnalysisEngine:
    def __init__(self, project_path: str = None):
        """Project Analysis EngineåˆæœŸåŒ–"""
        self.project_path = Path(project_path or os.getcwd())
        self.ai_hub_dir = Path(
            "/data/data/com.termux/files/home/ai-assistant-knowledge-hub"
        )
        self.temp_dir = self.ai_hub_dir / "temp"

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æçµæœ
        self.analysis_result = {
            "project_path": str(self.project_path),
            "project_structure": {},
            "project_purpose": {},
            "tech_stack": {},
            "architecture_patterns": {},
            "development_context": {},
        }

    def analyze_project_comprehensive(self) -> Dict:
        """åŒ…æ‹¬çš„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æå®Ÿè¡Œ"""
        print(f"ğŸ” ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æé–‹å§‹: {self.project_path}")

        # 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚¹ã‚­ãƒ£ãƒ³
        self._scan_project_structure()

        # 2. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›®çš„ãƒ»æ„å›³ã®ç†è§£
        self._analyze_project_purpose()

        # 3. æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ç‰¹å®š
        self._detect_tech_stack()

        # 4. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        self._analyze_architecture_patterns()

        # 5. é–‹ç™ºã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
        self._analyze_development_context()

        # 6. åˆ†æçµæœä¿å­˜
        self._save_analysis_result()

        print("âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æå®Œäº†")
        return self.analysis_result

    def _scan_project_structure(self):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚¹ã‚­ãƒ£ãƒ³"""
        print("ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚¹ã‚­ãƒ£ãƒ³ä¸­...")

        structure = {
            "root_files": [],
            "directories": [],
            "key_files": {},
            "file_counts": {},
            "total_files": 0,
        }

        try:
            # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»ãƒ•ã‚©ãƒ«ãƒ€å–å¾—
            for item in self.project_path.iterdir():
                if item.is_file():
                    structure["root_files"].append(item.name)
                elif item.is_dir() and not item.name.startswith("."):
                    structure["directories"].append(item.name)

            # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            key_files = [
                "package.json",
                "requirements.txt",
                "Cargo.toml",
                "go.mod",
                "README.md",
                "CLAUDE.md",
                "capacitor.config.json",
                "tsconfig.json",
                "webpack.config.js",
                "vite.config.js",
            ]

            for key_file in key_files:
                file_path = self.project_path / key_file
                if file_path.exists():
                    structure["key_files"][key_file] = str(file_path)

            # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
            structure["file_counts"] = self._count_files_by_extension()

            # ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°
            result = subprocess.run(
                ["find", str(self.project_path), "-type", "f", "!", "-path", "*/.*"],
                capture_output=True,
                text=True,
            )
            structure["total_files"] = (
                len(result.stdout.strip().split("\n")) if result.stdout.strip() else 0
            )

            self.analysis_result["project_structure"] = structure
            print(
                f"ğŸ“Š æ§‹é€ ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†: {structure['total_files']} files, {len(structure['directories'])} dirs"
            )

        except Exception as e:
            print(f"âš ï¸  æ§‹é€ ã‚¹ã‚­ãƒ£ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")

    def _count_files_by_extension(self) -> Dict[str, int]:
        """æ‹¡å¼µå­åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚«ã‚¦ãƒ³ãƒˆ"""
        file_counts = {}

        try:
            result = subprocess.run(
                ["find", str(self.project_path), "-type", "f", "!", "-path", "*/.*"],
                capture_output=True,
                text=True,
            )

            for file_path in result.stdout.strip().split("\n"):
                if file_path:
                    ext = Path(file_path).suffix.lower()
                    if ext:
                        file_counts[ext] = file_counts.get(ext, 0) + 1
                    else:
                        file_counts["no_extension"] = (
                            file_counts.get("no_extension", 0) + 1
                        )
        except:
            pass

        return file_counts

    def _analyze_project_purpose(self):
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›®çš„ãƒ»æ„å›³ã®ç†è§£"""
        print("ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›®çš„åˆ†æä¸­...")

        purpose = {
            "name": "",
            "description": "",
            "purpose": "",
            "features": [],
            "domain": "",
            "user_target": "",
        }

        # README.mdåˆ†æ
        readme_path = self.project_path / "README.md"
        if readme_path.exists():
            purpose.update(self._analyze_readme(readme_path))

        # package.jsonåˆ†æ (Node.js/Web ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ)
        package_json_path = self.project_path / "package.json"
        if package_json_path.exists():
            purpose.update(self._analyze_package_json(package_json_path))

        # CLAUDE.mdåˆ†æ
        claude_md_path = self.project_path / "CLAUDE.md"
        if claude_md_path.exists():
            purpose.update(self._analyze_claude_md(claude_md_path))

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‹ã‚‰æ¨æ¸¬
        if not purpose["name"]:
            purpose["name"] = self.project_path.name

        # ãƒ‰ãƒ¡ã‚¤ãƒ³æ¨æ¸¬
        purpose["domain"] = self._infer_project_domain(purpose)

        self.analysis_result["project_purpose"] = purpose
        print(f"ğŸ·ï¸  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç‰¹å®š: {purpose['name']} ({purpose['domain']})")

    def _analyze_readme(self, readme_path: Path) -> Dict:
        """README.mdåˆ†æ"""
        purpose_data = {}

        try:
            with open(readme_path, "r", encoding="utf-8") as f:
                content = f.read()

            # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
            title_match = re.search(r"^#\s+(.+)", content, re.MULTILINE)
            if title_match:
                purpose_data["name"] = title_match.group(1).strip()

            # èª¬æ˜æŠ½å‡º
            desc_match = re.search(
                r"#+\s*(Description|æ¦‚è¦|èª¬æ˜)\s*\n(.+?)(?=\n#+|\n\n|\Z)",
                content,
                re.DOTALL | re.IGNORECASE,
            )
            if desc_match:
                purpose_data["description"] = desc_match.group(2).strip()

            # æ©Ÿèƒ½ãƒªã‚¹ãƒˆæŠ½å‡º
            features = re.findall(r"[-*]\s+(.+)", content)
            if features:
                purpose_data["features"] = features[:10]  # æœ€å¤§10å€‹

        except Exception as e:
            print(f"âš ï¸  READMEåˆ†æã‚¨ãƒ©ãƒ¼: {e}")

        return purpose_data

    def _analyze_package_json(self, package_json_path: Path) -> Dict:
        """package.jsonåˆ†æ"""
        purpose_data = {}

        try:
            with open(package_json_path, "r", encoding="utf-8") as f:
                package_data = json.load(f)

            purpose_data["name"] = package_data.get("name", "")
            purpose_data["description"] = package_data.get("description", "")

            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰æ¨æ¸¬
            scripts = package_data.get("scripts", {})
            if "dev" in scripts or "serve" in scripts:
                purpose_data["purpose"] = "Web Development Project"

        except Exception as e:
            print(f"âš ï¸  package.jsonåˆ†æã‚¨ãƒ©ãƒ¼: {e}")

        return purpose_data

    def _analyze_claude_md(self, claude_md_path: Path) -> Dict:
        """CLAUDE.mdåˆ†æ"""
        purpose_data = {}

        try:
            with open(claude_md_path, "r", encoding="utf-8") as f:
                content = f.read()

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±æŠ½å‡º
            if "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ" in content or "Project" in content:
                purpose_data["user_target"] = "AIå”æ¥­é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ"

        except Exception as e:
            print(f"âš ï¸  CLAUDE.mdåˆ†æã‚¨ãƒ©ãƒ¼: {e}")

        return purpose_data

    def _infer_project_domain(self, purpose: Dict) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‰ãƒ¡ã‚¤ãƒ³æ¨æ¸¬"""
        name = purpose.get("name", "").lower()
        description = purpose.get("description", "").lower()
        features = " ".join(purpose.get("features", [])).lower()

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ‰ãƒ¡ã‚¤ãƒ³åˆ¤å®š
        if any(
            keyword in name + description + features
            for keyword in ["recipe", "ãƒ¬ã‚·ãƒ”", "cooking", "æ–™ç†"]
        ):
            return "Food/Recipe Application"
        elif any(
            keyword in name + description + features
            for keyword in ["mcp", "server", "api"]
        ):
            return "MCP Server/API"
        elif any(
            keyword in name + description + features
            for keyword in ["web", "app", "pwa"]
        ):
            return "Web Application"
        elif any(
            keyword in name + description + features
            for keyword in ["mobile", "android", "ios"]
        ):
            return "Mobile Application"
        else:
            return "General Development"

    def _detect_tech_stack(self):
        """æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ç‰¹å®š"""
        print("ğŸ”§ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯åˆ†æä¸­...")

        tech_stack = {
            "framework": [],
            "language": [],
            "build_tools": [],
            "mobile_platform": [],
            "database": [],
            "deployment": [],
        }

        # package.jsonåˆ†æ
        if "package.json" in self.analysis_result["project_structure"]["key_files"]:
            tech_stack.update(self._analyze_node_tech_stack())

        # Capacitoræ¤œå‡º
        if (
            "capacitor.config.json"
            in self.analysis_result["project_structure"]["key_files"]
        ):
            tech_stack["mobile_platform"].append("Capacitor")

        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã‹ã‚‰è¨€èªæ¨æ¸¬
        file_counts = self.analysis_result["project_structure"]["file_counts"]
        if ".js" in file_counts:
            tech_stack["language"].append("JavaScript")
        if ".ts" in file_counts:
            tech_stack["language"].append("TypeScript")
        if ".py" in file_counts:
            tech_stack["language"].append("Python")
        if ".html" in file_counts:
            tech_stack["framework"].append("Web/HTML")
        if ".css" in file_counts:
            tech_stack["framework"].append("CSS")

        self.analysis_result["tech_stack"] = tech_stack
        print(f"âš™ï¸  æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {', '.join(tech_stack.get('language', []))}")

    def _analyze_node_tech_stack(self) -> Dict:
        """Node.jsæŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯åˆ†æ"""
        tech_update = {"framework": [], "build_tools": []}

        try:
            package_json_path = self.analysis_result["project_structure"]["key_files"][
                "package.json"
            ]
            with open(package_json_path, "r", encoding="utf-8") as f:
                package_data = json.load(f)

            dependencies = {
                **package_data.get("dependencies", {}),
                **package_data.get("devDependencies", {}),
            }

            # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æ¤œå‡º
            framework_map = {
                "react": "React",
                "vue": "Vue.js",
                "angular": "Angular",
                "@capacitor/core": "Capacitor",
                "express": "Express.js",
            }

            for dep, framework in framework_map.items():
                if dep in dependencies:
                    tech_update["framework"].append(framework)

            # ãƒ“ãƒ«ãƒ‰ãƒ„ãƒ¼ãƒ«æ¤œå‡º
            build_tool_map = {
                "webpack": "Webpack",
                "vite": "Vite",
                "rollup": "Rollup",
                "esbuild": "ESBuild",
            }

            for dep, tool in build_tool_map.items():
                if dep in dependencies:
                    tech_update["build_tools"].append(tool)

        except Exception as e:
            print(f"âš ï¸  Node.jsæŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

        return tech_update

    def _analyze_architecture_patterns(self):
        """ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        print("ğŸ—ï¸  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æä¸­...")

        patterns = {
            "structure_type": "",
            "design_patterns": [],
            "file_organization": "",
            "complexity_level": "",
        }

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³æ¨æ¸¬
        directories = self.analysis_result["project_structure"]["directories"]

        if "src" in directories:
            patterns["structure_type"] = "Source-based Organization"
        if "lib" in directories and "workflows" in directories:
            patterns["structure_type"] = "Library/Workflow Organization"
        if "android" in directories or "ios" in directories:
            patterns["design_patterns"].append("Mobile Hybrid Pattern")

        # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‹ã‚‰è¤‡é›‘ã•æ¨æ¸¬
        total_files = self.analysis_result["project_structure"]["total_files"]
        if total_files < 20:
            patterns["complexity_level"] = "Simple"
        elif total_files < 100:
            patterns["complexity_level"] = "Medium"
        else:
            patterns["complexity_level"] = "Complex"

        self.analysis_result["architecture_patterns"] = patterns
        print(
            f"ğŸ›ï¸  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: {patterns['structure_type']} ({patterns['complexity_level']})"
        )

    def _analyze_development_context(self):
        """é–‹ç™ºã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ"""
        print("ğŸ‘¥ é–‹ç™ºã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æä¸­...")

        context = {
            "development_stage": "",
            "ai_integration": False,
            "collaboration_tools": [],
            "quality_tools": [],
            "development_approach": "",
        }

        # CLAUDE.mdã®å­˜åœ¨ç¢ºèª
        if "CLAUDE.md" in self.analysis_result["project_structure"]["key_files"]:
            context["ai_integration"] = True
            context["collaboration_tools"].append("Claude AI")

        # é–‹ç™ºãƒ„ãƒ¼ãƒ«æ¤œå‡º
        if ".gitignore" in self.analysis_result["project_structure"]["root_files"]:
            context["collaboration_tools"].append("Git")

        # package.jsonã‹ã‚‰ESLintç­‰æ¤œå‡º
        if "package.json" in self.analysis_result["project_structure"]["key_files"]:
            context.update(self._analyze_dev_tools_context())

        # é–‹ç™ºæ®µéšæ¨æ¸¬
        if self.analysis_result["project_structure"]["total_files"] > 50:
            context["development_stage"] = "Active Development"
        else:
            context["development_stage"] = "Early Stage"

        self.analysis_result["development_context"] = context
        print(f"ğŸš€ é–‹ç™ºæ®µéš: {context['development_stage']}")

    def _analyze_dev_tools_context(self) -> Dict:
        """é–‹ç™ºãƒ„ãƒ¼ãƒ«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ"""
        context_update = {"quality_tools": [], "development_approach": ""}

        try:
            package_json_path = self.analysis_result["project_structure"]["key_files"][
                "package.json"
            ]
            with open(package_json_path, "r", encoding="utf-8") as f:
                package_data = json.load(f)

            dev_dependencies = package_data.get("devDependencies", {})

            # å“è³ªãƒ„ãƒ¼ãƒ«æ¤œå‡º
            quality_tools = ["eslint", "prettier", "jest", "cypress", "typescript"]
            for tool in quality_tools:
                if tool in dev_dependencies:
                    context_update["quality_tools"].append(tool)

            # é–‹ç™ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒæ¨æ¸¬
            if "typescript" in dev_dependencies:
                context_update["development_approach"] = "Type-safe Development"
            elif "eslint" in dev_dependencies:
                context_update["development_approach"] = "Quality-focused Development"

        except Exception as e:
            print(f"âš ï¸  é–‹ç™ºãƒ„ãƒ¼ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

        return context_update

    def _save_analysis_result(self):
        """åˆ†æçµæœä¿å­˜"""
        self.temp_dir.mkdir(exist_ok=True)

        # Phase 2ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«
        analysis_file = self.temp_dir / f"phase2_analysis_{self.project_path.name}.json"

        with open(analysis_file, "w", encoding="utf-8") as f:
            json.dump(
                {
                    "phase": "2-project-analysis",
                    "timestamp": subprocess.check_output(["date"]).decode().strip(),
                    "project_name": self.project_path.name,
                    "analysis_result": self.analysis_result,
                },
                f,
                ensure_ascii=False,
                indent=2,
            )

        print(f"ğŸ’¾ åˆ†æçµæœä¿å­˜: {analysis_file}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    project_path = sys.argv[1] if len(sys.argv) > 1 else os.getcwd()

    try:
        # Project Analysis EngineåˆæœŸåŒ–
        analysis_engine = ProjectAnalysisEngine(project_path)

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æå®Ÿè¡Œ
        analysis_result = analysis_engine.analyze_project_comprehensive()

        print(f"ğŸ¯ Phase 2 å®Œäº†: {analysis_result['project_purpose']['name']}")
        print(
            f"ğŸ’¡ æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰: python {analysis_engine.ai_hub_dir}/workflows/phase3-requirements-analysis.py"
        )

    except Exception as e:
        print(f"âŒ Phase 2 ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
